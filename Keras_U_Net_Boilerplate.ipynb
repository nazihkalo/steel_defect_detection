{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Severstal_ Simple Keras U-Net Boilerplate.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazihkalo/steel_defect_detection/blob/master/Keras_U_Net_Boilerplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECyWcFt6eZG_",
        "colab_type": "text"
      },
      "source": [
        "# About this kernel\n",
        "\n",
        "This offers a boilerplate for a complete workflow for the Severstal Steel Defect Detection challenge. We will be using the popular U-Net architecture* in Keras, but I made this to be as extensible as possible so that you can experiment with different types of models. It is broken down in the following sections:\n",
        "\n",
        "* **Preprocessing**: Expand the train dataframe to include image ID. Also create `mask_count_df` which will be useful for later.\n",
        "* **Utility Functions**: Mostly copied from Paul's kernel and SIIM starter code (see references). You won't need to modify those.\n",
        "* **Sample Test**: Simply visualizing a sample image and its masks,\n",
        "* **Data Generator**: Very long and possibly complex. If you can, skip this part of the code. **If you absolute need to modify the data generation process, please take a look `__generate_X` and `__generate_y`**; in theory everything else should be left as is. \n",
        "* **Model Architecture**: The architecture is slightly different from the other kernels, since **it learns to predict all of the four masks at the same time**, instead of predicting a single mask and duplicating it. It also takes as input grayscale images.\n",
        "* **Training**: Running only for 9 epochs due to the time constraints (60 mins, this is roughly 300s per epoch).\n",
        "* **Evaluation & Submission**: The submission code is pretty messy. Essentially, I'm splitting the test dataframe into multiple chunks, then run the model and `mask2rle` converter on the results. I'm doing this in order to not run out of RAM as we try to convert all the masks from array to RLE.\n",
        "\n",
        "\n",
        "## Changelog\n",
        "\n",
        "V15: Added BCE-Dice loss, which should give slightly more accurate loss than pure binary cross-entropy (BCE).\n",
        "\n",
        "## References\n",
        "\n",
        "* Data generator: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "* RLE encoding and decoding: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
        "* Architecture: https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data\n",
        "* Mask encoding: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/data\n",
        "* Source for `bce_dice_loss`: https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-output": true,
        "id": "Ar094EYaeZHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRGyHvveZHE",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Yr8zgaHbeZHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n",
        "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
        "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
        "\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oM1d_wMjeZHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
        "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
        "print(mask_count_df.shape)\n",
        "mask_count_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y1SgmpjheZHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\n",
        "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfSTWWBeZHP",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions\n",
        "\n",
        "Source: https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVe-V8J3eZHQ",
        "colab_type": "text"
      },
      "source": [
        "## Mask encoding and decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZY3KCkPkeZHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle2mask(mask_rle, shape=(256,1600)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AmTDqsvceZHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_masks(rles, input_shape):\n",
        "    depth = len(rles)\n",
        "    height, width = input_shape\n",
        "    masks = np.zeros((height, width, depth))\n",
        "    \n",
        "    for i, rle in enumerate(rles):\n",
        "        if type(rle) is str:\n",
        "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
        "    \n",
        "    return masks\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpwCG0PoeZHW",
        "colab_type": "text"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be2GG_99eZHX",
        "colab_type": "text"
      },
      "source": [
        "Source for `bce_dice_loss`: https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dPogMNr5eZHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vPsL1fleZHa",
        "colab_type": "text"
      },
      "source": [
        "# Sample Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x_a5Tu2XeZHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_filename = 'db4867ee8.jpg'\n",
        "sample_image_df = train_df[train_df['ImageId'] == sample_filename]\n",
        "sample_path = f\"../input/severstal-steel-defect-detection/train_images/{sample_image_df['ImageId'].iloc[0]}\"\n",
        "sample_img = cv2.imread(sample_path)\n",
        "sample_rles = sample_image_df['EncodedPixels'].values\n",
        "sample_masks = build_masks(sample_rles, input_shape=(256, 1600))\n",
        "\n",
        "fig, axs = plt.subplots(5, figsize=(12, 12))\n",
        "axs[0].imshow(sample_img)\n",
        "axs[0].axis('off')\n",
        "\n",
        "for i in range(4):\n",
        "    axs[i+1].imshow(sample_masks[:, :, i])\n",
        "    axs[i+1].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leLWry7eeZHc",
        "colab_type": "text"
      },
      "source": [
        "# Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kCtnrxi1eZHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
        "                 base_path='../input/severstal-steel-defect-detection/train_images',\n",
        "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
        "                 n_classes=4, random_state=2019, shuffle=True):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.mode = mode\n",
        "        self.base_path = base_path\n",
        "        self.target_df = target_df\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
        "        \n",
        "        X = self.__generate_X(list_IDs_batch)\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "            y = self.__generate_y(list_IDs_batch)\n",
        "            return X, y\n",
        "        \n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "\n",
        "        else:\n",
        "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, list_IDs_batch):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            img_path = f\"{self.base_path}/{im_name}\"\n",
        "            img = self.__load_grayscale(img_path)\n",
        "            \n",
        "            # Store samples\n",
        "            X[i,] = img\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def __generate_y(self, list_IDs_batch):\n",
        "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "        \n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
        "            \n",
        "            rles = image_df['EncodedPixels'].values\n",
        "            masks = build_masks(rles, input_shape=self.dim)\n",
        "            \n",
        "            y[i, ] = masks\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __load_rgb(self, img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W4_qYwlgeZHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    mask_count_df.index, random_state=2019, test_size=0.15\n",
        ")\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    train_idx, \n",
        "    df=mask_count_df,\n",
        "    target_df=train_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    val_idx, \n",
        "    df=mask_count_df,\n",
        "    target_df=train_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ITBVhueZHg",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "The following model is directly taken from this awesome kernel: https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5MHHYclDeZHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
        "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
        "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
        "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
        "\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
        "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
        "\n",
        "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
        "    u6 = concatenate([u6, c5])\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
        "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
        "\n",
        "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u71 = concatenate([u71, c4])\n",
        "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
        "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
        "\n",
        "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
        "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
        "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
        "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47P167uceZHj",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Unhide below to see full summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "nVWiymoleZHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model((256, 1600, 1))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KJqWsQ9VeZHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor='val_dice_coef', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint],\n",
        "    use_multiprocessing=False,\n",
        "    workers=1,\n",
        "    epochs=7\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUWqi20deZHo",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation & Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K-BC7CjEeZHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('history.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['dice_coef', 'val_dice_coef']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WHzEFE2peZHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model.h5')\n",
        "test_df = []\n",
        "\n",
        "for i in range(0, test_imgs.shape[0], 500):\n",
        "    batch_idx = list(\n",
        "        range(i, min(test_imgs.shape[0], i + 500))\n",
        "    )\n",
        "    \n",
        "    test_generator = DataGenerator(\n",
        "        batch_idx,\n",
        "        df=test_imgs,\n",
        "        shuffle=False,\n",
        "        mode='predict',\n",
        "        base_path='../input/severstal-steel-defect-detection/test_images',\n",
        "        target_df=sub_df,\n",
        "        batch_size=1,\n",
        "        n_classes=4\n",
        "    )\n",
        "    \n",
        "    batch_pred_masks = model.predict_generator(\n",
        "        test_generator, \n",
        "        workers=1,\n",
        "        verbose=1,\n",
        "        use_multiprocessing=False\n",
        "    )\n",
        "    \n",
        "    for j, b in tqdm(enumerate(batch_idx)):\n",
        "        filename = test_imgs['ImageId'].iloc[b]\n",
        "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
        "        \n",
        "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
        "        pred_rles = build_rles(pred_masks)\n",
        "        \n",
        "        image_df['EncodedPixels'] = pred_rles\n",
        "        test_df.append(image_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "moqmV30EeZHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.concat(test_df)\n",
        "test_df.drop(columns='ImageId', inplace=True)\n",
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}